{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RMA-943Aev9e"
   },
   "source": [
    "# Spiking multicompartment PC network\n",
    "\n",
    "## Abstract\n",
    "Predictive coding is a promising theoretical framework for understanding the hierarchical sensory processing in the brain, yet how it is implemented with cortical spiking neurons is still unclear. While most existing works have taken a hand-wiring approach to creating microcircuits which match experimental results, recent work in applying the optimisation approach revealed that cortical connectivity might result from self-organisation given some fundamental computational principle, ie. energy efficiency. We thus investigated whether predictive coding properties in a multicompartment spiking neural network can result from energy optimisation. We found that only the model trained with an energy objective in addition to a task-relevant objective was able to reconstruct internal representations given top-down expectation signals alone. Neurons in the energy-optimised model also showed differential responses to expected vs unexpected stimuli, qualitatively similar to experimental evidence for predictive coding. These findings indicated that predictive-coding-like behaviour might be an emergent property of energy optimisation, providing a new perspective on how predictive coding could be achieved in the cortex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9e5fUxmZcxfc",
    "outputId": "87a4b8e1-ab15-4a24-dc7e-20a6796837c3"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn import init\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "import os\n",
    "import pandas as pd\n",
    "import math\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from predcoding.snn.network import SnnNetwork3Layer\n",
    "from predcoding.training import train_fptt, get_stats_named_params, reset_named_params\n",
    "from predcoding.snn.experiments.eval import test\n",
    "from predcoding.utils import count_parameters, save_checkpoint\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# set seed\n",
    "torch.manual_seed(999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qNZglAYUfXQF",
    "outputId": "1e81f699-656e-425f-b289-71eeff15ab2a"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.5), (0.5))]\n",
    ")\n",
    "\n",
    "batch_size = 200\n",
    "\n",
    "traindata = torchvision.datasets.MNIST(\n",
    "    root=\"./data\", train=True, download=True, transform=transform\n",
    ")\n",
    "\n",
    "testdata = torchvision.datasets.MNIST(\n",
    "    root=\"./data\", train=False, download=True, transform=transform\n",
    ")\n",
    "\n",
    "# data loading\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    traindata, batch_size=batch_size, shuffle=False, num_workers=2\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    testdata, batch_size=batch_size, shuffle=False, num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R_DORsdsg-TS"
   },
   "source": [
    "## Defining the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oaqFPBCFg0vF"
   },
   "outputs": [],
   "source": [
    "# network parameters\n",
    "adap_neuron = True  # whether use adaptive neuron or not\n",
    "clf_alpha = 1\n",
    "energy_alpha = 0.05  # - config.clf_alpha\n",
    "spike_alpha = 0.0  # energy loss on spikes\n",
    "num_readout = 10\n",
    "onetoone = True\n",
    "lr = 1e-3\n",
    "alg = \"fptt\"\n",
    "dp = 0.4\n",
    "is_rec = False\n",
    "\n",
    "\n",
    "# training parameters\n",
    "T = 50\n",
    "K = 10  # k_updates is num updates per sequence\n",
    "omega = int(T / K)  # update frequency\n",
    "clip = 1.0\n",
    "log_interval = 20\n",
    "epochs = 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1d1UjhDUjV45",
    "outputId": "7d1ee2d2-8484-4744-c6c8-606b2ad1f912"
   },
   "outputs": [],
   "source": [
    "# set input and t param\n",
    "IN_dim = 784\n",
    "hidden_dim = [600, 500, 500]\n",
    "n_classes = 10\n",
    "\n",
    "# define network\n",
    "model = SnnNetwork3Layer(\n",
    "    IN_dim,\n",
    "    hidden_dim,\n",
    "    n_classes,\n",
    "    is_adapt=adap_neuron,\n",
    "    one_to_one=onetoone,\n",
    "    dp_rate=dp,\n",
    "    is_rec=is_rec,\n",
    ")\n",
    "model.to(device)\n",
    "print(model)\n",
    "\n",
    "# define new loss and optimiser\n",
    "total_params = count_parameters(model)\n",
    "print(\"total param count %i\" % total_params)\n",
    "\n",
    "# define optimiser\n",
    "optimizer = optim.Adamax(model.parameters(), lr=lr, weight_decay=0.0001)\n",
    "# reduce the learning after 20 epochs by a factor of 10\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EA-seG48koNP"
   },
   "source": [
    "## Train & test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CVlGea6ClBuJ",
    "outputId": "d6beec93-15da-49f4-b3ba-a126b2bcc2fd"
   },
   "outputs": [],
   "source": [
    "# untrained network\n",
    "test_loss, acc1 = test(model, test_loader, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mq_ifdLDkDY4",
    "outputId": "988e9a43-d50f-4f14-b933-e952d1a650c0"
   },
   "outputs": [],
   "source": [
    "named_params = get_stats_named_params(model)\n",
    "all_test_losses = []\n",
    "best_acc1 = 20\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_fptt(\n",
    "        epoch,\n",
    "        batch_size,\n",
    "        log_interval,\n",
    "        train_loader,\n",
    "        model,\n",
    "        named_params,\n",
    "        T,\n",
    "        K,\n",
    "        omega,\n",
    "        optimizer,\n",
    "        clf_alpha,\n",
    "        energy_alpha,\n",
    "        spike_alpha,\n",
    "        clip,\n",
    "        lr,\n",
    "    )\n",
    "\n",
    "    reset_named_params(named_params)\n",
    "\n",
    "    test_loss, acc1 = test(model, test_loader, T)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    # remember best acc@1 and save checkpoint\n",
    "    is_best = acc1 > best_acc1\n",
    "    best_acc1 = max(acc1, best_acc1)\n",
    "\n",
    "    if is_best:\n",
    "        save_checkpoint(\n",
    "            {\n",
    "                \"epoch\": epoch + 1,\n",
    "                \"state_dict\": model.state_dict(),\n",
    "                # 'oracle_state_dict': oracle.state_dict(),\n",
    "                \"best_acc1\": best_acc1,\n",
    "                \"optimizer\": optimizer.state_dict(),\n",
    "                # 'oracle_optimizer' : oracle_optim.state_dict(),\n",
    "            },\n",
    "            is_best,\n",
    "            prefix=\"voltage_diff_\",\n",
    "            filename=\"best.pth.tar\",\n",
    "        )\n",
    "\n",
    "    all_test_losses.append(test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "__LVbhpNtdnv"
   },
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oqt82T4Kxe3b"
   },
   "outputs": [],
   "source": [
    "def get_states(\n",
    "    hiddens_all_: list, idx: int, hidden_dim_: int, batch_size, T=20, num_samples=10000\n",
    "):\n",
    "    \"\"\"\n",
    "    get a particular internal state depending on index passed to hidden\n",
    "\n",
    "    Args:\n",
    "        hidden_dim_: the size of a state, eg. num of r or p neurons\n",
    "        T: total time steps\n",
    "        hiddens_all_: list containing hidden states of all batch and time steps during inference\n",
    "        idx: which index in h is taken out\n",
    "    Returns: \n",
    "        np.array containing desired states\n",
    "    \"\"\"\n",
    "\n",
    "    all_states = []\n",
    "\n",
    "    for batch_idx in range(len(hiddens_all_)):  # iterate over batch\n",
    "        batch_ = []\n",
    "        for t in range(T):\n",
    "            seq_ = []\n",
    "            for b in range(batch_size):\n",
    "                seq_.append(hiddens_all_[batch_idx][t][idx][b].detach().cpu().numpy())\n",
    "            seq_ = np.stack(seq_)\n",
    "            batch_.append(seq_)\n",
    "        batch_ = np.stack(batch_)\n",
    "\n",
    "        all_states.append(batch_)\n",
    "\n",
    "    all_states = np.stack(all_states)\n",
    "\n",
    "    return all_states.transpose(0, 2, 1, 3).reshape(num_samples, T, hidden_dim_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B8wz4RNylrN9",
    "outputId": "6b3f5908-cbd7-4319-a375-a0a48408175a"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test(model, test_loader, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "ClgkQ-_UCZZ8",
    "outputId": "1e95ee88-3915-4c47-e14b-1cc7a0c7c4f0"
   },
   "outputs": [],
   "source": [
    "# saved_dict = model_result_dict_load('/content/onelayer_rec_best.pth.tar')\n",
    "# model.load_state_dict(saved_dict['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gG1lxK_jEumU",
    "outputId": "cbfb3a92-bbe2-4794-b415-1b851f6177e7"
   },
   "outputs": [],
   "source": [
    "# get params and put into dict\n",
    "param_names_wE = []\n",
    "param_dict_wE = {}\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        param_names_wE.append(name)\n",
    "\n",
    "print(param_names_wE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9vAePjZCCjok",
    "outputId": "94d15376-38f3-45df-a5f3-da21d33fc3bd"
   },
   "outputs": [],
   "source": [
    "# clamped generation of internal representations\n",
    "no_input = torch.zeros((1, IN_dim)).to(device)\n",
    "clamp_T = T * 5\n",
    "\n",
    "\n",
    "l1_clamp_E = np.zeros((10, hidden_dim[0]))\n",
    "l2_clamp_E = np.zeros((10, hidden_dim[1]))\n",
    "l3_clamp_E = np.zeros((10, hidden_dim[2]))\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        hidden_i = model.init_hidden(1)\n",
    "\n",
    "        _, hidden_gen_E_ = model.clamped_generate(i, no_input, hidden_i, clamp_T, clamp_value=1)\n",
    "\n",
    "        #\n",
    "        l1_E = get_states([hidden_gen_E_], 1, hidden_dim[0], 1, clamp_T, num_samples=1)\n",
    "        l2_E = get_states([hidden_gen_E_], 5, hidden_dim[1], 1, clamp_T, num_samples=1)\n",
    "        l3_E = get_states([hidden_gen_E_], 9, hidden_dim[2], 1, clamp_T, num_samples=1)\n",
    "\n",
    "        l1_clamp_E[i] += np.squeeze(l1_E.mean(axis=1))\n",
    "        l2_clamp_E[i] += np.squeeze(l2_E.mean(axis=1))\n",
    "        l3_clamp_E[i] += np.squeeze(l3_E.mean(axis=1))\n",
    "\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "tKb_uqaaw0Te",
    "outputId": "cea965e2-0fb3-4e46-c9c8-e6749192100d"
   },
   "outputs": [],
   "source": [
    "##############################################################\n",
    "# decode from clamped representations\n",
    "##############################################################\n",
    "no_input = torch.zeros((1, IN_dim)).to(device)\n",
    "\n",
    "MSE_loss = nn.MSELoss()\n",
    "\n",
    "test_loader2 = torch.utils.data.DataLoader(\n",
    "    testdata, batch_size=batch_size, shuffle=False, num_workers=2\n",
    ")\n",
    "\n",
    "\n",
    "# %%\n",
    "def plot_projection(rep, label, weights, bias):\n",
    "    img = (weights @ rep + bias).reshape(28, 28)\n",
    "    plt.imshow(img)\n",
    "    plt.title(str(label))\n",
    "    plt.show()\n",
    "    return img\n",
    "\n",
    "\n",
    "# %%\n",
    "layer = 1\n",
    "l2_E_decoder, loss_E = train_linear_proj(layer, model)\n",
    "\n",
    "decoders = [l2_E_decoder]\n",
    "\n",
    "# %%\n",
    "# plot loss curve of training\n",
    "colors = [\n",
    "    (0.1271049596309112, 0.4401845444059977, 0.7074971164936563),\n",
    "    (0.9949711649365629, 0.5974778931180315, 0.15949250288350636),\n",
    "]\n",
    "sns.set_style(\"whitegrid\", {\"axes.grid\": False})\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 4))\n",
    "plt.rcParams.update({\"font.size\": 14})\n",
    "\n",
    "ax.plot(loss_E, label=\"Energy L%i\" % (layer + 1), color=colors[0])\n",
    "ax.legend()\n",
    "# frame off\n",
    "ax.spines[[\"right\", \"top\"]].set_visible(False)\n",
    "ax.set_ylabel(\"MES loss\")\n",
    "ax.set_xlabel(\"steps\")\n",
    "plt.legend(frameon=False)\n",
    "# increase font size\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 188
    },
    "id": "R3b_S8msxjWN",
    "outputId": "06ddf57d-e697-4878-be6d-f26652668595"
   },
   "outputs": [],
   "source": [
    "# plot decoding of clamped internal representations\n",
    "fig, axes = plt.subplots(1, 10, figsize=(10, 2))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for proj_class in range(n_classes):\n",
    "        img1 = (\n",
    "            decoders[0](\n",
    "                torch.tensor(l2_clamp_E[proj_class].astype(\"float32\"))\n",
    "                .to(device)\n",
    "                .view(-1, hidden_dim[layer])\n",
    "            )\n",
    "            .reshape(28, 28)\n",
    "            .cpu()\n",
    "        )\n",
    "        axes[proj_class].imshow(img1, cmap=\"viridis\")\n",
    "        axes[proj_class].set_title(str(proj_class))\n",
    "        # axes[0][proj_class].axis('off')\n",
    "        axes[proj_class].tick_params(\n",
    "            left=False, right=False, labelleft=False, labelbottom=False, bottom=False\n",
    "        )\n",
    "\n",
    "fig.suptitle(\"projection from clampled rep back to image plane layer %i\" % (layer + 1))\n",
    "axes[0].set_ylabel(\"Energy\", rotation=0, labelpad=40)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NfPXz2_qBjxm"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
